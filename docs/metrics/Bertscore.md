# BertScore

Class for evaluating the similarity between a generated response and one or more expected responses using embeddings from a pre-trained transformer model.

## Initialization

The `BertScore` class is initialized with the following parameters:

- **llm_response**: The response generated by a language model.
- **retrieval_context**: The expected response(s) to compare against the actual response.
- **model_name**: The identifier for the pre-trained transformer model to use for generating embeddings.
- **max_length**: The maximum length of input sequences to be processed by the model.

```python
import torch
from transformers import AutoTokenizer, AutoModel
import numpy as np
from typing import Union, List, Dict

class BertScore:
    def __init__(
        self,
        llm_response
        retrieval_context,
        model_name = "roberta-base",
        max_length = 1024,
    ):
        """
        Initialize the BertScore class to evaluate the similarity between a generated response
        and one or more expected responses using a specified pre-trained transformer model.

        Parameters:
        llm_response (str): The response generated by a language model.
        retrieval_context (Union[str, List[str]]): The expected response(s) to compare against the actual response.
        model_name (str): The identifier for the pre-trained model to be used for generating embeddings.
                          Defaults to "roberta-base".
        max_length (int): The maximum length of input sequences to be processed by the model. Defaults to 1024.
        """
```
## Parameters Explanation

- **llm_response**: The actual response generated by the language model that needs to be evaluated.

- **retrieval_context**: The expected responses for comparison. Can be a single string or a list of strings.

- **model_name**: The name of the pre-trained transformer model used for generating text embeddings. Default is `"roberta-base"`.

- **max_length**: The maximum length for input sequences that the model will handle. Default is `1024`.

## Usage Example

Here is an example of how to use the `BertScore` class:

```python
from indox.IndoxEval import BertScore, Evaluator

# Define a sample response and context
llm_response = "The quick brown fox jumps over the lazy dog."
retrieval_context = [
    "The fast brown fox leaps over the lazy dog.",
    "A speedy brown fox jumps over a sleepy dog."
]

# Initialize the BertScore object
bert_score = BertScore(
    llm_response=llm_response,
    retrieval_context=retrieval_context,
    model_name="roberta-base",
    max_length=512
)

# Measure the similarity
evaluator = Evaluator(model=None, metrics=[bert_score])
result = evaluator.evaluate()
```