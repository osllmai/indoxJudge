# BLEU

Class for evaluating the similarity between a generated response and one or more expected responses using the BLEU metric, which is based on n-gram overlaps.

## Initialization

The `BLEU` class is initialized with the following parameters:

- **llm_response**: The response generated by a language model.
- **retrieval_context**: The expected response(s) to compare against the actual response.
- **n**: The maximum size of the n-grams to use for evaluation.
- **remove_repeating_ngrams**: Option to remove repeating n-grams from consideration.

```python
class BLEU:
    def __init__(
        self,
        llm_response: str,
        retrieval_context: Union[str, List[str]],
        n: int = 2,
        remove_repeating_ngrams: bool = False,
    ):
        """
        Initialize the BLEU evaluator with the desired n-gram size and option to remove repeating n-grams.

        Parameters:
        llm_response (str): The response generated by a language model.
        retrieval_context (Union[str, List[str]]): The expected response(s) to compare against the actual response.
        n (int): The maximum size of the n-grams to use for evaluation (default is 2).
        remove_repeating_ngrams (bool): Whether to remove repeating n-grams (default is False).
        """
```
## Parameters Explanation

- **llm_response**: The actual response generated by the language model that needs to be evaluated.

- **retrieval_context**: The expected responses for comparison. Can be a single string or a list of strings.

- **n**: The maximum n-gram size to use for evaluation. Default is `2`.

- **remove_repeating_ngrams**: A boolean flag to indicate whether to remove repeating n-grams from consideration. Default is `False`.
## Usage Example

Here is an example of how to use the `BLEU` class:

```python
from indoxJudge.metrics import BLEU
from indoxJudge.pipelines import CustomEvaluator

# Define a sample response and context
llm_response = "The quick brown fox jumps over the lazy dog."
retrieval_context = [
    "The fast brown fox leaps over the lazy dog.",
    "A speedy brown fox jumps over a sleepy dog."
]

# Initialize the BLEU object
bleu = BLEU(
    llm_response=llm_response,
    retrieval_context=retrieval_context,
    n=2,
    remove_repeating_ngrams=False
)

# Measure the BLEU score
evaluator = CustomEvaluator(model=None, metrics=[bleu])
result = evaluator.judge()
```