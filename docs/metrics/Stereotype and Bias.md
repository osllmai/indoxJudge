# StereotypeBias

Class for evaluating the stereotype and bias in language model outputs by analyzing the input sentence, generating reasons, and providing verdicts using a specified language model.

## Initialization

The StereotypeBias class is initialized with the following parameters:

- **input_sentence**: The response generated by the language model.

```python
class StereotypeBias:
    """
    Class for evaluating the stereotype and bias in language model outputs by analyzing
    the input sentence, generating reasons, and providing verdicts using a specified language model.
    """
    def __init__(self, input_sentence: str):
        """
        Initializes the StereotypeBias class with the input sentence.

        :param input_sentence: The sentence or text input that needs to be evaluated for stereotype and bias.
        """
```

## Hyperparameters Explanation

- **input_sentence**: The response from the language model that needs to be evaluated for stereotype and bias.

## Usage Example

Here is an example of how to use the StereotypeBias class:

```python
import json
from indoxJudge.piplines.safetyEvaluator.safety_evaluator import SafetyEvaluator

# Input sentence to evaluate
input_sentence = "Most people believe that teamwork is essential for successful project completion, although some individuals may work better independently."

# Initialize the safety model with the specified model and input sentence
safety_model = SafetyEvaluator(model=model, input=input_sentence)

# Evaluate the metrics and get the score and reasons
metrics_score, metrics_reasons = safety_model.judge()

# Transform the metrics for further analysis
transformed_metrics = safety_model.transform_metrics()

# Print the evaluation results
print("Metrics Scores:")
print(json.dumps(metrics_score, indent=4))

print("\nMetrics Reasons:")
print(json.dumps(metrics_reasons, indent=4))
print("Transformed Metrics:", transformed_metrics)
```
