# Bias

Class for evaluating potential bias in language model outputs by analyzing opinions, generating verdicts, and calculating bias scores.

## Initialization

The `Bias` class is initialized with the following parameters:

- **llm_response**: The response generated by the language model.
- **threshold**: The threshold for determining bias. Defaults to `0.5`.
- **include_reason**: Whether to include reasoning for the bias verdicts. Defaults to `True`.
- **strict_mode**: Whether to use strict mode, which forces a score of 1 if bias exceeds the threshold. Defaults to `False`.

```python
class Bias:
    """
    Class for evaluating potential bias in language model outputs by analyzing opinions,
    generating verdicts, and calculating bias scores.
    """
    def __init__(self, llm_response, threshold: float = 0.5, include_reason: bool = True, strict_mode: bool = False):
        """
        Initializes the Bias class with the LLM response and evaluation settings.

        :param llm_response: The response generated by the language model.
        :param threshold: The threshold for determining bias. Defaults to 0.5.
        :param include_reason: Whether to include reasoning for the bias verdicts. Defaults to True.
        :param strict_mode: Whether to use strict mode, which forces a score of 1 if bias exceeds the threshold. Defaults to False.
        """
```

# Hyperparameters Explanation

- **llm_response**: The response from the language model that is being evaluated for bias.

- **threshold**: A float value representing the bias threshold. If the bias score exceeds this threshold, the output may be flagged as biased. The default value is 0.5.

- **include_reason**: A boolean that determines whether the evaluation should include reasoning for why a certain bias score was assigned. Default is True.

- **strict_mode**: A boolean that, when set to True, forces a score of 1 if the bias exceeds the threshold, regardless of the exact score. This is useful for stringent bias detection. Default is False.

# Usage Example

Here is an example of how to use the `Bias` class:

```python
import os
from dotenv import load_dotenv
from indoxJudge.models import OpenAi
from indoxJudge.metrics import Bias
from indoxJudge.pipelines import Evaluator
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# Initialize the language model
# it can be any OpenAI model, please refer to the [OpenAI Models documentation](https://platform.openai.com/docs/models) such as GPT-4o.

llm = OpenAi(api_key=OPENAI_API_KEY, model="Open AI Model")

# Define the query and the response to be evaluated
query = "What is the capital of France?"
llm_response = "The capital of France is Paris."

# Initialize the evaluation metrics
bias_metric = Bias(llm_response=llm_response, threshold=0.5, include_reason=True, strict_mode=False)

# Initialize the Evaluator with the model and metrics
evaluator = Evaluator(model=llm, metrics=[bias_metric])
result = evaluator.judge()
```
