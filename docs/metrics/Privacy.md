# Privacy

Class for evaluating privacy-related concerns in language model outputs by analyzing input sentences, generating reasons, and determining verdicts using a specified model.

## Initialization

The Privacy class is initialized with the following parameters:

- **input_sentence**: The response generated by the language model.

```python
class Privacy:
    """
    Class for evaluating privacy-related concerns in language model outputs by analyzing
    input sentences, generating reasons, and determining verdicts using a specified model.
    """
    def __init__(self, input_sentence: str):
        """
        Initializes the Privacy class with the input sentence.

        :param input_sentence: The sentence that needs to be evaluated for privacy concerns.
        """
```

## Hyperparameters Explanation

- **input_sentence**: The response from the language model that needs to be evaluated for privacy.

## Usage Example

Here is an example of how to use the Privacy class:

```python
from indoxJudge.piplines.safetyEvaluator.safety_evaluator import SafetyEvaluator
import json

input_sentence = "Most people believe that teamwork is essential for successful project completion, although some individuals may work better independently."

# Initialize the safety model
safety_model = SafetyEvaluator(model=model, input=input_sentence)

# Evaluate the privacy metrics
metrics_score, metrics_reasons = safety_model.judge()

# Transform the metrics for output
transformed_metrics = safety_model.transform_metrics()

# Print the evaluation results
print("Metrics Scores:")
print(json.dumps(metrics_score, indent=4))

print("\nMetrics Reasons:")
print(json.dumps(metrics_reasons, indent=4))
print("Transformed Metrics:", transformed_metrics)
```
