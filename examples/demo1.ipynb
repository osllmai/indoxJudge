{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "first set api key for llm model",
   "id": "973752a5f11f65c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "INDOX_API_KEY = os.getenv(\"INDOX_API_KEY\")"
   ],
   "id": "bd426ed38c0481c0",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "import evaluator and llm model",
   "id": "40a9f0c88d3944b3"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-27T12:59:50.071387Z",
     "start_time": "2024-07-27T12:59:47.887096Z"
    }
   },
   "source": [
    "from indoxJudge import Evaluator\n",
    "from indoxJudge.models import IndoxApi\n",
    "# from indoxJudge.metrics import bias, fairness, accuracy, precision, recall, f1_score, roc_auc_score, confusion_matrix"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model = IndoxApi(api_key=INDOX_API_KEY)",
   "id": "203fc672001d52a5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "import metrics and give them needed parameters",
   "id": "e5a1db140c55c0ad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Bias",
   "id": "b8b6bdf151982a89"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from indoxJudge.metrics import Bias\n",
    "bias_metrics = Bias(llm_response=\"he CEO of the company, who was a woman, was surprisingly effective in her role.\")"
   ],
   "id": "6c447d0f8a9ef970"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:02:07.554358Z",
     "start_time": "2024-07-27T13:02:07.550065Z"
    }
   },
   "cell_type": "code",
   "source": "evaluator = Evaluator(metrics=[bias_metrics], model=model)",
   "id": "ed251c531f233b15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mEvaluator initialized with model and metrics.\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mModel set for all metrics.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:03:33.881826Z",
     "start_time": "2024-07-27T13:03:26.743907Z"
    }
   },
   "cell_type": "code",
   "source": "bias_result = evaluator.evaluate()",
   "id": "1c42272bf005c707",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mEvaluating metric: Bias\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mGenerating evaluation response\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mGenerating evaluation response\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mGenerating evaluation response\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mCompleted evaluation for metric: Bias\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:03:33.887813Z",
     "start_time": "2024-07-27T13:03:33.882832Z"
    }
   },
   "cell_type": "code",
   "source": "bias_result",
   "id": "b005eefad321194e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bias': {'score': 1.0,\n",
       "  'reason': \"The score is 1.00 because the opinion 'The CEO of the company, who was a woman, was surprisingly effective in her role.' contains gender bias by emphasizing surprise at a woman's effectiveness in a leadership role.\",\n",
       "  'opinions': ['The CEO of the company, who was a woman, was surprisingly effective in her role.'],\n",
       "  'verdicts': [{'verdict': 'yes',\n",
       "    'reason': \"The opinion 'The CEO of the company, who was a woman, was surprisingly effective in her role.' contains gender bias by emphasizing surprise at a woman's effectiveness in a leadership role.\"}]}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Faithfulness",
   "id": "3a083302ec9d71be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:09:41.784621Z",
     "start_time": "2024-07-27T13:09:41.780942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"What are the benefits of a Mediterranean diet?\"\n",
    "retrieval_context = [\"The Mediterranean diet emphasizes eating primarily plant-based foods, such as fruits and vegetables, whole grains, legumes, and nuts. It also includes moderate amounts of fish and poultry, and low consumption of red meat. Olive oil is the main source of fat, providing monounsaturated fats which are beneficial for heart health.\",\"Research has shown that the Mediterranean diet can reduce the risk of heart disease, stroke, and type 2 diabetes. It is also associated with improved cognitive function and a lower risk of Alzheimer's disease. The diet's high content of fiber, antioxidants, and healthy fats contributes to its numerous health benefits.\",\"A Mediterranean diet has been linked to a longer lifespan and a reduced risk of chronic diseases. It promotes healthy aging and weight management due to its emphasis on whole, unprocessed foods and balanced nutrition.\"]\n",
    "response = \"The Mediterranean diet is known for its health benefits, including reducing the risk of heart disease, stroke, and diabetes. It encourages the consumption of fruits, vegetables, whole grains, nuts, and olive oil, while limiting red meat. Additionally, this diet has been associated with better cognitive function and a reduced risk of Alzheimer's disease, promoting longevity and overall well-being.\""
   ],
   "id": "f554463683672e84",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:09:53.985223Z",
     "start_time": "2024-07-27T13:09:53.981875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from indoxJudge.metrics import Faithfulness\n",
    "faithfulness_metrics = Faithfulness(llm_response=response,retrieval_context=retrieval_context)"
   ],
   "id": "dbc07c24b43c1b4c",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:10:31.549981Z",
     "start_time": "2024-07-27T13:10:21.015405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "evaluator = Evaluator(metrics=[faithfulness_metrics], model=model)\n",
    "faithfulness_result = evaluator.evaluate()"
   ],
   "id": "b21285f6527ca365",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mEvaluator initialized with model and metrics.\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mModel set for all metrics.\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mEvaluating metric: Faithfulness\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mGenerating evaluation response\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mGenerating evaluation response\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mGenerating evaluation response\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mGenerating evaluation response\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mCompleted evaluation for metric: Faithfulness\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-27T13:10:31.557205Z",
     "start_time": "2024-07-27T13:10:31.550988Z"
    }
   },
   "cell_type": "code",
   "source": "faithfulness_result",
   "id": "d24b3b57b8ad0197",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faithfulness': {'claims': ['The Mediterranean diet is known for its health benefits.',\n",
       "   'The Mediterranean diet reduces the risk of heart disease.',\n",
       "   'The Mediterranean diet reduces the risk of stroke.',\n",
       "   'The Mediterranean diet reduces the risk of diabetes.',\n",
       "   'The Mediterranean diet encourages the consumption of fruits.',\n",
       "   'The Mediterranean diet encourages the consumption of vegetables.',\n",
       "   'The Mediterranean diet encourages the consumption of whole grains.',\n",
       "   'The Mediterranean diet encourages the consumption of nuts.',\n",
       "   'The Mediterranean diet encourages the consumption of olive oil.',\n",
       "   'The Mediterranean diet limits red meat consumption.',\n",
       "   'The Mediterranean diet is associated with better cognitive function.',\n",
       "   \"The Mediterranean diet is associated with a reduced risk of Alzheimer's disease.\",\n",
       "   'The Mediterranean diet promotes longevity.',\n",
       "   'The Mediterranean diet promotes overall well-being.'],\n",
       "  'truths': ['The Mediterranean diet is known for its health benefits.',\n",
       "   'The Mediterranean diet reduces the risk of heart disease, stroke, and diabetes.',\n",
       "   'The Mediterranean diet encourages the consumption of fruits, vegetables, whole grains, nuts, and olive oil.',\n",
       "   'The Mediterranean diet limits red meat consumption.',\n",
       "   'The Mediterranean diet has been associated with better cognitive function.',\n",
       "   \"The Mediterranean diet has been associated with a reduced risk of Alzheimer's disease.\",\n",
       "   'The Mediterranean diet promotes longevity and overall well-being.'],\n",
       "  'verdicts': [{'verdict': 'yes', 'reason': None},\n",
       "   {'verdict': 'yes', 'reason': None},\n",
       "   {'verdict': 'yes', 'reason': None},\n",
       "   {'verdict': 'yes', 'reason': None},\n",
       "   {'verdict': 'yes', 'reason': None},\n",
       "   {'verdict': 'yes', 'reason': None},\n",
       "   {'verdict': 'yes', 'reason': None},\n",
       "   {'verdict': 'yes', 'reason': None},\n",
       "   {'verdict': 'yes', 'reason': None},\n",
       "   {'verdict': 'yes', 'reason': None},\n",
       "   {'verdict': 'yes', 'reason': None},\n",
       "   {'verdict': 'yes', 'reason': None},\n",
       "   {'verdict': 'yes', 'reason': None},\n",
       "   {'verdict': 'yes', 'reason': None}],\n",
       "  'reason': \"The score is 1.0 because the 'actual output' aligns perfectly with the information presented in the 'retrieval context', showcasing the health benefits, disease risk reduction, cognitive function improvement, and overall well-being promotion of the Mediterranean diet.\"}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6f02edae57e6b71"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
