{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "683cbd8af3980e07",
   "metadata": {
    "id": "683cbd8af3980e07"
   },
   "source": [
    "# Safety Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5413162f477c5781",
   "metadata": {
    "id": "5413162f477c5781"
   },
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/osllmai/inDoxJudge/blob/main/examples/safety_evaluator.ipynb)"
  },
  {
   "cell_type": "code",
   "id": "59547c8b03b3fd98",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "59547c8b03b3fd98",
    "outputId": "bd064a8d-94e3-40d5-c7bb-245cdca448b1",
    "ExecuteTime": {
     "end_time": "2024-08-29T08:32:30.202070Z",
     "start_time": "2024-08-29T08:32:30.186444Z"
    }
   },
   "source": [
    "!pip install indoxJudge -U\n",
    "!pip install python-dotenv openai"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "c259ce9e5cffc8c0",
   "metadata": {
    "id": "c259ce9e5cffc8c0"
   },
   "source": [
    "## Setting Up the Python Environment\n",
    "\n",
    "If you are running this project in your local IDE, please create a Python environment to ensure all dependencies are correctly managed. You can follow the steps below to set up a virtual environment named `indoxJudge`:\n",
    "\n",
    "### Windows\n",
    "\n",
    "1. **Create the virtual environment:**\n",
    "```bash\n",
    "python -m venv indoxJudge\n",
    "```\n",
    "2. **Activate the virtual environment:**\n",
    "```bash\n",
    "indoxJudge\\Scripts\\activate\n",
    "```\n",
    "\n",
    "### macOS/Linux\n",
    "\n",
    "1. **Create the virtual environment:**\n",
    "   ```bash\n",
    "   python3 -m venv indoxJudge\n",
    "```\n",
    "\n",
    "2. **Activate the virtual environment:**\n",
    "    ```bash\n",
    "   source indoxJudge/bin/activate\n",
    "```\n",
    "### Install Dependencies\n",
    "\n",
    "Once the virtual environment is activated, install the required dependencies by running:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "id": "initial_id",
    "ExecuteTime": {
     "end_time": "2024-08-29T08:32:30.237960Z",
     "start_time": "2024-08-29T08:32:30.206666Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "c243c048e503e90f",
   "metadata": {
    "id": "c243c048e503e90f",
    "ExecuteTime": {
     "end_time": "2024-08-29T08:32:30.253550Z",
     "start_time": "2024-08-29T08:32:30.237960Z"
    }
   },
   "source": [
    "response = \"The Mediterranean diet is known for its health benefits, including reducing the risk of heart disease, stroke, and diabetes. It encourages the consumption of fruits, vegetables, whole grains, nuts, and olive oil, while limiting red meat. Additionally, this diet has been associated with better cognitive function and a reduced risk of Alzheimer's disease, promoting longevity and overall well-being.\""
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "65529ced4f6beb0b",
   "metadata": {
    "id": "65529ced4f6beb0b"
   },
   "source": [
    "## Importing Required Modules\n",
    "imports the necessary classes from the indoxJudge library. SafetyEvaluator is the class used for evaluating language models based on various metrics, and OpenAi is the class used to interact with the OpenAI models, such as GPT-3.5."
   ]
  },
  {
   "cell_type": "code",
   "id": "57511dda37de77a4",
   "metadata": {
    "id": "57511dda37de77a4",
    "ExecuteTime": {
     "end_time": "2024-08-29T08:32:33.854751Z",
     "start_time": "2024-08-29T08:32:30.253550Z"
    }
   },
   "source": [
    "from indoxJudge.piplines import SafetyEvaluator\n",
    "from indoxJudge.models import OpenAi"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "14599bd20a3d8f5d",
   "metadata": {
    "id": "14599bd20a3d8f5d"
   },
   "source": [
    "## Initializing the OpenAI Model\n",
    "Here, the OpenAi class is instantiated to create a model object that interacts with OpenAI's gpt-3.5-turbo-0125 model. The api_key is passed to authenticate the API request. Replace OPENAI_API_KEY with your actual API key."
   ]
  },
  {
   "cell_type": "code",
   "id": "b8f0ad7b798f17c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8f0ad7b798f17c9",
    "outputId": "a09a38ef-b18b-4ff8-b840-097857d2240d",
    "ExecuteTime": {
     "end_time": "2024-08-29T08:32:33.870285Z",
     "start_time": "2024-08-29T08:32:33.854751Z"
    }
   },
   "source": "model = OpenAi(api_key=OPENAI_API_KEY,model=\"gpt-3.5-turbo-0125\")",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "53d8bf90524259fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "53d8bf90524259fa",
    "outputId": "c6d3de02-b7a2-4779-85cb-03c05793b86e",
    "ExecuteTime": {
     "end_time": "2024-08-29T08:32:33.885908Z",
     "start_time": "2024-08-29T08:32:33.870285Z"
    }
   },
   "source": [
    "evaluator = SafetyEvaluator(model=model, input=response)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mEvaluator initialized with model and metrics.\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mModel set for all metrics.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "b11a2ae0a78d3b70",
   "metadata": {
    "id": "b11a2ae0a78d3b70"
   },
   "source": [
    "**Explanation:**\n",
    "\n",
    "- **Running the Evaluation:** This line calls the `judge` method on the `evaluator` object. The `judge` method runs through all the specified metrics (e.g., Fairness, Harmfulness, Privacy, Misinformation, StereotypeBias, MachineEthics) to evaluate the language model's performance.\n",
    "  \n",
    "- **Logging the Process:** As the evaluation runs, the process logs the start and completion of each metric evaluation, providing feedback on the progress. Each log entry is tagged with an INFO level, indicating routine operational messages.\n",
    "  \n",
    "- **Handling Warnings:** You may notice a warning regarding model initialization and a future deprecation notice from the Hugging Face Transformers library. These warnings inform you about potential issues related to model compatibility and upcoming changes in the library.\n",
    "  \n",
    "- **Evaluate Metrics:** This line calls the `judge` method on the `evaluator` instance. It is expected to return two values: `metrics_score` and `metrics_reasons`. `metrics_score`  contains the evaluation scores for various metrics, and `metrics_reasons` provides explanations or justifications for the scores.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "af324b3695562eb2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "af324b3695562eb2",
    "outputId": "0cd0a58f-8e7e-4e49-99cd-5d6a3a149ea7",
    "ExecuteTime": {
     "end_time": "2024-08-29T08:39:16.870835Z",
     "start_time": "2024-08-29T08:32:33.885908Z"
    }
   },
   "source": [
    "eval_result = evaluator.judge()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mEvaluating metric: Fairness\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mCompleted evaluation for metric: Fairness\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mEvaluating metric: Harmfulness\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mCompleted evaluation for metric: Harmfulness\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mEvaluating metric: Privacy\u001B[0m\n",
      "\u001B[32mERROR\u001B[0m: \u001B[31m\u001B[1mError generating evaluation response: HTTPConnectionPool(host='5.78.55.161', port=80): Read timed out. (read timeout=None)\u001B[0m\n",
      "\u001B[31mERROR\u001B[0m: \u001B[31m\u001B[1mError generating evaluation response: HTTPConnectionPool(host='5.78.55.161', port=80): Read timed out. (read timeout=None)\u001B[0m\n",
      "Error decoding JSON: Expecting value: line 1 column 1 (char 0)\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mCompleted evaluation for metric: Privacy\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mEvaluating metric: Misinformation\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mCompleted evaluation for metric: Misinformation\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mEvaluating metric: MachineEthics\u001B[0m\n",
      "\u001B[32mERROR\u001B[0m: \u001B[31m\u001B[1mError generating evaluation response: HTTPConnectionPool(host='5.78.55.161', port=80): Read timed out. (read timeout=None)\u001B[0m\n",
      "\u001B[31mERROR\u001B[0m: \u001B[31m\u001B[1mError generating evaluation response: HTTPConnectionPool(host='5.78.55.161', port=80): Read timed out. (read timeout=None)\u001B[0m\n",
      "Error decoding JSON: Expecting value: line 1 column 1 (char 0)\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mCompleted evaluation for metric: MachineEthics\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mEvaluating metric: StereotypeBias\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mCompleted evaluation for metric: StereotypeBias\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mEvaluating metric: SafetyToxicity\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mCompleted evaluation for metric: SafetyToxicity\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mEvaluating metric: AdversarialRobustness\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mCompleted evaluation for metric: AdversarialRobustness\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mEvaluating metric: RobustnessToAdversarialDemonstrations\u001B[0m\n",
      "Error decoding JSON: Expecting value: line 1 column 1 (char 0)\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mCompleted evaluation for metric: RobustnessToAdversarialDemonstrations\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mEvaluating metric: OutOfDistributionRobustness\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mCompleted evaluation for metric: OutOfDistributionRobustness\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T08:39:16.887200Z",
     "start_time": "2024-08-29T08:39:16.870835Z"
    }
   },
   "cell_type": "code",
   "source": "evaluator_metrics_score = evaluator.metrics_score",
   "id": "c7dfc53f5e24137",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T08:39:16.940070Z",
     "start_time": "2024-08-29T08:39:16.891199Z"
    }
   },
   "cell_type": "code",
   "source": "evaluator_metrics_score",
   "id": "57d78bf6da437ac2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fairness': 1.0,\n",
       " 'Harmfulness': 0.1,\n",
       " 'Privacy': 0.2,\n",
       " 'Misinformation': 1.0,\n",
       " 'MachineEthics': 0.0,\n",
       " 'StereotypeBias': 0.2,\n",
       " 'Toxicity': 0.0,\n",
       " 'AdversarialRobustness': 0.2,\n",
       " 'RobustnessToAdversarialDemonstrations': 0.2,\n",
       " 'OutOfDistributionRobustness': 0.9,\n",
       " 'evaluation_score': 0.3}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "5bdd339ed8bc5be6",
   "metadata": {
    "id": "5bdd339ed8bc5be6"
   },
   "source": [
    "**Explanation:**\n",
    "\n",
    "- **Plotting Evaluation Metrics:** This line generates visual plots of the evaluation metrics using the `plot` method of the `evaluator` object. The plots provide a graphical representation of the model's performance across different metrics, making it easier to analyze and compare the results.\n",
    "\n",
    "- **Dash UI Interface:** When `mode=\"external\"` is used, this will open a Dash UI in a new browser window or tab to display the evaluation metrics plots interactively.\n",
    "\n",
    "- **Colab Users:** If you are using Google Colab, it is recommended to set `mode=\"inline\"` instead. This will render the plots directly within the notebook, making it more convenient for users working in an online environment like Colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "f1ca2f3ea94d1ee7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "f1ca2f3ea94d1ee7",
    "outputId": "a2258c8a-eb3d-412f-ab11-053b2f348ca5",
    "ExecuteTime": {
     "end_time": "2024-08-29T08:40:23.844645Z",
     "start_time": "2024-08-29T08:40:23.617851Z"
    }
   },
   "source": "evaluator.plot(mode=\"external\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T08:39:20.402035Z",
     "start_time": "2024-08-29T08:39:20.386060Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b75f5a9aa22ee021",
   "outputs": [],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
